ViT(AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE)
**V****i**sion**T**ransformer

基于Self-Attention结构的神经网络已经成为NLP类网络的标配， 目前主流训练方法为在大的语料库上pre-train，然后再在一个小的数据集上进行finetune.

ViT相比传统CV网络性能有显著的的提升。
